\documentclass{stdlocal}
\begin{document}
\section{Introduction} % (fold)
\label{sec:introduction}

For various mathematical and physical problems, there exists no feasible, deterministic algorithm to solve them.
Especially, the simulations of physical systems with many coupled degrees of freedom, such as fluids and global illumination, seem to be difficult to compute due to their high dimensionality.
Instead, a class of randomized algorithms, called Monte Carlo methods, are used to approximate the actual outcome.
Monte Carlo methods rely on repeated random sampling to obtain a numerical result.
Hence, they are not bound to the \enquote{curse of dimensionality} and are able to quickly evaluate complex equations.
\autocite{pharr2016,bauke2007,mueller2012,landau2014}\footnote{In this thesis, citations concerning a whole paragraph will be given after the last sentence.}

To obtain precise answers with a small relative error, Monte Carlo algorithms have to use a tremendous amount of random numbers.
But the usage of truly random numbers generated by physical processes consists at least of two drawbacks.
First, the output of the algorithm will be non-deterministic and, as a result, untestable.
Second, the generation of truly random numbers is typically based on a slow process and consequently reduces the performance of the entire program.
For that reason, Monte Carlo algorithms usually use so-called pseudorandom number generators (PRNGs).
PRNGs generate a sequence of numbers based on a deterministic procedure and a truly random initial value as seed.
The sequence of numbers is not truly random but fulfills several properties of truly random sequences.
\autocite{bauke2007,intel-drng,lecuyer1994,lecuyer2015,lecuyer2017,volchan2002}

The structure of Monte Carlo methods causes a program to spend most of its time with the construction of random numbers.
Even the application of PRNGs does not change that.
Today's computer processors provide functionality for the parallel execution of code in different ways, mainly single instruction multiple data (SIMD) and multiple instruction multiple data (MIMD).
Hence, to efficiently use the computing power of a processor for Monte Carlo algorithms not bound by memory, PRNGs have to be vectorized and parallelized to exploit such features.
Whereas parallelization takes place at a high level, vectorization has to be done by the compiler or manually by the programmer at a much lower level.
The implementation of PRNGs constrains automatic vectorization due to internal flow and data dependencies.
To lift this restriction, a manual vectorization concerning data dependence and latencies appears to be the right way.
Often, there are already manually vectorized algorithms that need to use random numbers, such as in \textcite{blacher2018}.
As a consequence, vectorizing PRNGs is even essential to provide the utilities for these implementations.
\autocite{lecuyer2017,bauke2007,hennessy2019,patterson2014,barash2017,dolbeau2016,intel-optimization-reference,fog2019a,fog2019b,fog2019c,fog2019d,fog2019e}

The C++ programming language is an adequate candidate for the development of vectorized PRNGs.
It is one of the most used programming languages in the world and can be applied to small research projects as well as large enterprise programs.
C++ allows for the high-level abstraction of algorithms and structures.
On the other hand, it is capable of accessing low-level routines to exploit special hardware features, like Intel's Streaming SIMD Extensions (SSE), Intel's Advanced Vector Extensions (AVX), and threads.
A typical C++ compiler is able to optimize the code with respect to such features automatically.
But we as programmers are not bound to this and can manually optimize the code further.
Every three years, a new standard is published, such as the latest language specification called C++17.
The language is evolving by its communities improvements and therefore it keeps to be modern.
On top of this, other languages, such as Python, usually provide an interface to communicate with the C programming language.
Through the design of an efficient implementation in C++, we can easily add support for other languages as well by providing a standard C interface.
\autocite{stroustrup2014,meyers2014,vandevoorde2018,intel-intrinsics-guide,reddy2011,cppreference,isocpp}

Lots of PRNGs have been implemented by different libraries with different Application Programming Interfaces (APIs), such as the STL of C++, \citetitle{boost}, \citetitle{intel-mkl}, and \citetitle{rngavxlib}.
For example, the STL and \citetitle{boost} provide a large set of robust PRNGs which are not vectorized but well documented.
Their API makes them likely to be used but shows some flaws.
It does not allow to explicitly use the vectorization capabilities of a PRNG and gives you a bad default seeding.
The use of standard distributions is difficult and not adjustable.
\citetitle{rngavxlib} provides highly optimized, open-source, vectorized implementations with bad documentation and difficult-to-use code.
The \citetitle{intel-mkl}, too, provides vectorized PRNGs, but is not available as open-source and uses difficult-to-use interfaces.
Besides complete libraries, there are also standalone implementations of vectorized PRNGs in \textcite{lemire-pcg} and \textcite{lemire-xorshift}.
So far, there has been no easily-accessible, portable, and open-source software library written in C++ which gives a coherent, easy-to-use and consistent interface for vectorized PRNGs.
\autocite{intel-mkl,boost,guskova2016,oneill-blog-api,gcc-libstdcpp}

In this thesis, precisely in sections \ref{sec:design_of_the_api} and \ref{sec:implementation}, we develop a new library, called \citetitle{pxart}, in the C++ programming language \footfullcite{pxart}.
\citetitle{pxart} vectorizes a few already known PRNGs which partly do not exist as vectorized versions and provides a new API for their usage to accommodate the disadvantages of the random facilities of the STL.
The library itself is header-only, open-source, and can be found on GitHub.
It is easily installable on every operating system.
% Additionally, we compare the performance of our vectorized PRNGs to other already accessible implementations in Boost, Intel MKL, Lemire, RNGAVXLIB and others.
% The performance is measured by speed, code size, memory size, complexity, and random properties.
The necessary theoretical background to understand the design- and the implementation-specific aspects is given in the sections \ref{sub:preliminaries}, \ref{sub:simulation_in_physics_and_mathematics}, and \ref{sec:pseudorandom_number_generators}.
Here, we will give a brief introduction to computer architecture, Monte Carlo methods and random sequences.
Especially, section \ref{sec:pseudorandom_number_generators} will give a mathematically rigorous introduction to PRNGs to make the reader familiar with the topic.
Section \ref{sec:previous_work} refers to the previous work concerning the vectorization of PRNGs.
% Meanwhile, we apply the implementations to an example Monte Carlo simulation.
% For this, a small test framework is implemented which allows us to easily test and evaluate PRNGs with respect to stated measures.
To show that our vectorized implementations result in a performance improvement without reducing the statistical quality of generated random numbers, we have used standard test suites, namely \citetitle{dieharder} and \citetitle{testu01-lib}, and created benchmarks to measure the actual speed-up in section \ref{sec:testing_framework}.
At the end, we have designed an application based on Monte Carlo algorithms to simulate essential parts of photon propagation and global illumination to show the usage of our PRNGs in the context of physics.
In the sections \ref{sec:evaluation} and \ref{sec:conclusions}, the evaluation is shown followed by a discussion dealing with further improvements.
\autocite{dieharder,testu01-lib,testu01}

% section introduction (end)
\end{document}