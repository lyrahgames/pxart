\documentclass{stdlocal}
\begin{document}
\section{Previous Work} % (fold)
\label{sec:previous_work}
  In the last few years, the vectorization of PRNGs has not received great attention.
  We will give a brief overview of the major contributions concerning the implementation of vectorized PRNGs.

  Because the SIMD routines are a form of data-level parallelism, their application to PRNGs has to exploit the facility of multiple streams for small generators to take full advantage of the whole size of vector registers.
  According to \textcite{fog2015}, there is a number of techniques to initialize multiple, independent pseudorandom streams for vector registers.
  One of it uses multiple instances of the same generator with different seeds.
  This method can lead to overlapping subsequences.
  \citeauthor{fog2015} calculates the probability of this to happen and gives an example of when to ignore a possible overlap.
  Some PRNGs offer a jump-ahead feature which can be used to initialize all instances with only one seed.
  Each stream will then be a non-overlapping subsequence of the same generator with certain length.
  There are families of PRNGs that are described by the same algorithm only differing in their underlying parameters.
  Using different sets of parameters for every instance will generate independent streams.
  If the PRNG has a larger state size, like the MT19937, we do not have to deal with multiple instances of the same generator.
  Instead, multiple streams can be generated by computation of consecutive elements.
  \citeauthor{fog2015} compares these methods and gives a general advice.
  Furthermore, he explains that it will be better to combine different generators for superior statistical properties.
  But this approach has no direct impact on vectorization techniques as we first have to discuss the implementation of the stand-alone generators.
  Combining those will then be a trivial operation that will be not be discussed here.

  \textcite{saito2008} presented an alternative algorithm, called SFMT, to the widely used Mersenne Twister optimized for the SSE instruction set which is working with $128\appendUnit{bit}$ data types.
  The authors have been one of the first people to officially vectorize PRNGs.
  They provide a library for academic usage and could successfully show that their generation scheme is much more efficient when using SSE based instructions.
  On the other hand, processor architectures are evolving.
  Using the SFMT on modern hardware with AVX or even AVX512 support will not make full use of the complete vector registers because the algorithm is specialized for the older SSE registers.

  With \citetitle{intel-mkl}, \citeauthor{intel-mkl} provides a high-performance library for C and C++ exploiting the features and microarchitectures of Intel processors.
  Besides optimized mathematical functions, they also provide several different implementations of vectorized PRNGs ready to be used after linking the library.
  Especially we get variants of the standard Mersenne Twister MT19937 and the SFMT to name the most common generators.
  Because they develop their own CPUs, Intel is able to create fine-tuned code for nearly every given microarchitecture resulting in a high-quality of their implementations.
  However, the source code of the library is not open source and cannot be easily adjusted for differing architectures that are not built by Intel.
  Furthermore, the interface to use the routines of the library tend to be complicated and due to their backwards compatibility it is unlikely that this will change.

  \textcite{barash2017} describes how to implement a lot of PRNGs by using the AVX instruction set.
  They as well provide a library for academic use with an implementation of the MT19937 even surpassing Intel's implementation.
  But the interface of the library is again C-compatible and introduces an overhead in development time while using C++.
  \citeauthor{barash2017} manually vectorize their code through inline assembly statements which make their code unreadable, difficult to understand and not generalizable to other SIMD architectures.

  In \textcite{lemire-pcg} and \textcite{lemire-xorshift}, \citeauthor{lemire-pcg} supplies two open source code snippets for the vectorization of a PCG and a Xorshift generator with the AVX and AVX512 instruction sets by using Intel intrinsics.
  Therefore the code is well suited for analyzing the application of SIMD intrinsics to PRNGs and comparing different vectorization schemes.
  His implementations are not tested and not well documented.

  \textcite{vigna-xoroshiro} presents a modern PRNG with good statistical properties.
  In his explanation, \citeauthor{vigna-xoroshiro} talks about triggering automatic vectorization by using four independent streams of the named generator.
  He mentions, that it sometimes seems to be difficult to successfully force the compiler to generate vector intrinsics.
  As a consequence, a manual vectorization technique should be much more appropriate as we will show in the next sections.

  According to the explanations and descriptions given, we have chosen to vectorize another variant of the MT19937 with the SSE and AVX instruction set because, even if it shows some statistical flaws and has a big state, it is the de facto standard for current applications.
  Additionally, the MT19937 is reliable, has an extremely long period, can be used for multidimensional simulations and will perfectly serve as an academic example on how to vectorize a PRNG.
  Furthermore, we will show how to implement two PRNGs with the SSE and AVX instruction set, namely the Xoroshiro128+ and the MSWS, which were not vectorized yet.
  The idea is to raise the performance of the Xoroshiro128+ in comparison to an automatic vectorization process.
  The MSWS is non-linear but fast and modern generator for which we have to use a slightly different vectorization technique.
  All this will give us an insight into the vectorization of PRNGs.
% section previous_work (end)
\end{document}