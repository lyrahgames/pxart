\documentclass[crop=false]{stdlocal}
\begin{document}
\section{Conclusions and Future Work} % (fold)
\label{sec:conclusions}
  We were able to show that the vectorization of PRNGs and distributions based on SIMD intrinsics can improve the performance of physical simulations, such as the propagation of photons, which need to access a large amount of random numbers.
  By applying current statistical and empirical test suites, it was demonstrated that the vectorization of multiple instances does not reduce the statistical performance of the given generators.
  The time and effort taken to implement the vectorized data structures and advancing routines do not outweigh the enhancement in speed-up but have to be considered when deciding to vectorize an actual application to further increase performance.
  We made clear that measuring the performance of PRNGs in general should be done inside an actual application that is using random numbers to compute a testable result to not falsify outcomes.

  Also, we have developed an API which makes the initialization process and the usage of distributions much simpler while providing possibilities for easily implementing new generators specializing algorithms though the creation of certain member functions.
  The interface of the library was directly applied to the testing framework and the physical simulations showing its simplicity and robustness.
  Accelerating the execution of randomized algorithms was achieved through different implementation schemes by using scalar code or exploiting SSE/AVX features.
  Especially, the estimation of Ï€ and the simulation of photon propagation typically build the basis for more advanced physical simulations in optics and quantum physics depending on Monte Carlo integration, Metropolis-Hastings algorithms, importance sampling and Russian roulette.
  Thus, even in scalar applications not using any SIMD intrinsics, we can recommend the usage of vectorized PRNGs and distributions to speed up the generation of random numbers.

  For further development, we recommend to compare our implementations against vectorized state-of-the-art RNGs given by \citetitle{intel-mkl} and \citetitle{rngavxlib}.
  Due to the unique restrictions concerning the statistical performance an application is imposing on an RNG, future work should involve the development of even more vectorized RNGs.
  This also means that we have to exhaustively test the statistical performance of vectorized PRNGs in different scenarios.
  These scenarios should be simplified versions of a real-world problem to justify the results and examine the robustness of our current design.
  By tweaking the testing and benchmarking framework, we are then able to extend the vectorized implementations to other SIMD architectures providing vector registers, like the AVX512 instruction set from Intel.
  With the release of the C++20 standard specification, we should take advantage on the newly introduced features of C++, like concepts, to reduce the complexity of the API and increase its performance and handling.

  In our implementations, we did not optimize the SIMD code to exploit every single issue concerning the latency and throughput of instructions.
  Doing so would involve a much larger output size when calling an advancing routine.
  In general, we have to use multiple independent instances to be able to reorder the instructions and to keep the processor pipeline filled as a consequence.
  We have only needed one SIMD vector of random numbers per call to not introduce arrays of random numbers that may not fit into the caches.
  However, users of a software library that is providing random facilities frequently want to generate large arrays of random numbers.
  So enhancements to the library should involve the latency- and throughput-based optimization of PRNGs.
  This should be done in such a way that the user is able to choose which vectorized variant best suits his needs.

  Applying vectorized PRNGs to applications which were not vectorized, yet, can typically be done by introducing a small cache with the size of the generator output.
  A further increase in performance is then achieved by vectorizing the application.
  This task is known to be time-consuming, exhaustive, and error-prone.
  As a consequence, a future version of the software library should provide an SIMD wrapper class to simplify the usage of intrinsics without reducing their performance.
  Wrapping SIMD intrinsics was already done by \citeauthor{fog2019a} \autocite{fog2019a} and a lot of other people.
  All wrappers are used in different contexts and therefore provide a different API that makes their integration into \citetitle{pxart} difficult.
  Instead, we would need a new and C++-aware interface which makes the usage of PRNGs easier but on the other hand is able to be implicitly constructed from and converted to low-level SIMD intrinsics.
  This would not constrain the integration of other wrapper classes or the direct use of intrinsics.
  Furthermore, it enables us to exploit the template metaprogramming features of the C++ programming language.

  Aside from the direct optimization of PRNGs, \citetitle{pxart} should exhibit a reacher interface for different seeding mechanisms and distributions.
  For example, to enable good deterministic seeding by using a varying amount of fixed integers, a general default seeder based on \textcite{oneill-blog-seed-seq} should be implemented.
  There are applications which need to use different distributions, like Gaussian distributions or uniform integer distributions.
  Using their scalar versions from the STL of the C++ programming language would reduce the overall performance and therefore making the use of vectorized PRNGs futile.
  For these special situations, vectorized implementations of varying seeding mechanisms and distributions should be considered in the development.

  Finally, further development should take care of thread-based parallelism.
  Currently, the user of the library has to manually initialize the generators in different threads of a program.
  This process should be automated such that the use of vectorized PRNGs in many threads guarantees non-overlapping subsequences up to a certain amount of random numbers.
  % To find a good design and test such utilities, we again need real-world applications.
% section conclusions (end)
\end{document}